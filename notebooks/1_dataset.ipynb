{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedleyDB dataset\n",
    "This project uses the [MedleyDB dataset](https://medleydb.weebly.com/) V1 (and V2). To get access to the dataset, you need to ask for permission through Zenodo. \\\n",
    "This notebook is created to explore the MedleyDB dataset. There is an overview of the dataset here: https://medleydb.weebly.com/description.html \\\n",
    "Fortunately, the authors provides a sample of the dataset here: https://zenodo.org/record/1438309#.Y9dniuxBy3I. The sample set contains 2 songs from V1:\n",
    "1. LizNelson_Rainfall\n",
    "2. Phoenix_ScotchMorris\n",
    "\n",
    "## Setups\n",
    "To correctly setup the medleydb library, the `medleydb/medleydb/data/` folder need to have the structure below:\n",
    "```\n",
    "medleydb #sub-module\n",
    "├── medleydb\n",
    "│   ├── data\n",
    "│   │   ├── Annotations\n",
    "│   │   ├── Audio\n",
    "│   │   └── Metadata\n",
    "...\n",
    "```\n",
    "Simply rename `V1` or `V2` folder after extracting to `Audio` and put it inside the `data/` folder above. \\\n",
    "For the MedleyDB Sample (2 songs) simply copy-paste `Audio` folder into `data/`.\n",
    "\n",
    "For accessibility, we will try to use only the 2 songs in the sample set for making example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pitch_tracker.utils import files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If import medleydb return `TypeError: load() missing 1 required positional argument: 'Loader'`, you need to downgrade pyyaml:\n",
    "```\n",
    "pyyaml==5.4.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to a forked medleydb repo https://github.com/duotien/medleydb\n",
    "MEDLEYDB_REPO_PATH = f\"{os.getcwd()}/../medleydb/\"\n",
    "MEDLEY_DB_DATA_PATH = os.path.join(MEDLEYDB_REPO_PATH, 'medleydb/data/')\n",
    "print(MEDLEY_DB_DATA_PATH)\n",
    "os.environ['MEDLEYDB_PATH'] = MEDLEY_DB_DATA_PATH\n",
    "import medleydb\n",
    "from pitch_tracker.utils.medleydb_melody import gen_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate annotations\n",
    "medleyDB also has tools for customizing the annotations. However you need to have the audio for it to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOP = 512*5\n",
    "output_dir = f'../content/gen_label/{HOP}'\n",
    "AUDIO_PATH = medleydb.AUDIO_PATH\n",
    "\n",
    "available_tracks = list(files.list_folder_paths_in_dir(AUDIO_PATH))\n",
    "available_tracks = [files.get_file_name(full_path) for full_path in available_tracks]\n",
    "\n",
    "mtracks = medleydb.load_multitracks(available_tracks)\n",
    "\n",
    "for mtrack in mtracks:\n",
    "    gen_label(mtrack.track_id, output_dir, hop=HOP, overwrite=True, convert_to_midi=True, round_method='round', to_csv=True)\n",
    "    # gen_label(mtrack.track_id, output_dir, hop=HOP, overwrite=True, convert_to_midi=True, round_method='round', to_csv=False)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_1_path, melody_2_path, *_ = [os.path.join(output_dir, folder_path) for folder_path in os.listdir(output_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_2_annotation_paths = []\n",
    "for root, folders, files in os.walk(melody_2_path):\n",
    "    melody_2_annotation_paths.extend([os.path.join(root, fpath) for fpath in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation_path = random.choice(melody_2_annotation_paths)\n",
    "print(sample_annotation_path)\n",
    "df = pd.read_csv(sample_annotation_path, names=['start', 'end', 'midi_value'])\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise\n",
    "We recommend using Sonic Visualiser to visualize the annotations with audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to visualize using matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "from librosa.display import specshow, waveshow\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(signal: np.ndarray, sample_rate:int, convert_to_mel:bool=False,offset:int=0, n_frame:int=None, f_ratio=1, n_mels:int=108, **stft_params):\n",
    "    if len(signal.shape) == 1:\n",
    "        signal = np.expand_dims(signal, axis=0)\n",
    "    if n_frame is not None:\n",
    "        signal = signal[:,offset:offset+n_frame]\n",
    "    \n",
    "    # Apply FFT & Calculate the Magnitude Spectrum\n",
    "\n",
    "\n",
    "    if convert_to_mel:\n",
    "        S = librosa.feature.melspectrogram(y=signal, sr=sample_rate, **stft_params, n_mels=n_mels)\n",
    "        S_log = librosa.power_to_db(S, ref=np.max)\n",
    "        y_axis = 'mel'\n",
    "\n",
    "    else:\n",
    "        S = librosa.stft(y=signal, **stft_params)\n",
    "        S_log = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "        y_axis = 'linear'\n",
    "\n",
    "    num_channels, num_frames = signal.shape\n",
    "    figure, axes = plt.subplots(nrows=num_channels, ncols=1)\n",
    "\n",
    "    # frequency = np.linspace(0, sample_rate, num_frames)\n",
    "    # num_frequency_bins = int(len(frequency)*f_ratio)\n",
    "\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        # axes[c].plot(frequency[:num_frequency_bins], magnitude_spectrum[c,:num_frequency_bins])\n",
    "        im = specshow(S_log[c], sr=sample_rate, x_axis='time', y_axis=y_axis, ax=axes[c])\n",
    "        # axes[c].grid(True)\n",
    "        axes[c].label_outer()\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(\"Spectrogram\")\n",
    "    figure.colorbar(im, ax=axes, format=\"%+2.0f dB\")\n",
    "\n",
    "    plt.show(block=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '../medleydb/medleydb/data/Audio/Phoenix_ScotchMorris/Phoenix_ScotchMorris_MIX.wav'\n",
    "metadata = torchaudio.info(audio_path)\n",
    "signal, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "song_duration = metadata.num_frames/metadata.sample_rate # in seconds\n",
    "m,s = divmod(song_duration, 60)\n",
    "print(metadata)\n",
    "print(f'Song duration: {song_duration:.2f}s ({m:.0f}m{s:.0f}s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params = {\n",
    "    'n_fft': 1024,\n",
    "    'win_length': None,\n",
    "    'hop_length': 512,\n",
    "    'window': \"hann\",\n",
    "    'center': True,\n",
    "    'dtype': None,\n",
    "    'pad_mode': \"constant\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(signal.numpy(), sample_rate, convert_to_mel=False, offset=0, n_frame=10*sample_rate, **stft_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52beeaf2f359c8a16806d5f0d8f5873f1371a44c8d29b1d1f26a131eb5378aea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
