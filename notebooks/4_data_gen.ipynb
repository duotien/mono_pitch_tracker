{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a data generator that yeild the features and labels\n",
    "# we first need to cut the audio into frames\n",
    "# then get the labels to fit those frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut audio into frames\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pitch_tracker.utils.constants import (F_MIN, HOP_LENGTH, N_FFT, N_MELS,\n",
    "                                           PICKING_FRAME_SIZE,\n",
    "                                           PICKING_FRAME_STEP,\n",
    "                                           PICKING_FRAME_TIME, SAMPLE_RATE,\n",
    "                                           STEP_FRAME, STEP_TIME, WIN_LENGTH,\n",
    "                                           N_CLASS, )\n",
    "from pitch_tracker.utils.audio import load_audio_mono\n",
    "from pitch_tracker.utils.files import get_file_name, list_file_paths_in_dir\n",
    "\n",
    "from pitch_tracker.utils import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '../medleydb/medleydb/data/Audio/Phoenix_ScotchMorris/Phoenix_ScotchMorris_MIX.wav'\n",
    "signal, sample_rate = load_audio_mono(audio_path, SAMPLE_RATE, keep_channel_dim=True)\n",
    "# signal = torch.unsqueeze(signal,0)\n",
    "# signal = torch.from_numpy(signal)\n",
    "mel_features = dataset.extract_melspectrogram_feature(signal,N_FFT, HOP_LENGTH, N_MELS, SAMPLE_RATE, backend='librosa')\n",
    "print(mel_features.shape)\n",
    "\n",
    "stft_feature = dataset.extract_stft_feature(signal, N_FFT, HOP_LENGTH)\n",
    "print(stft_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../content/gen_label/2560/Melody2_midi/AClassicEducation_NightOwl.csv'\n",
    "csv_folder = '../content/gen_label/2560/Melody2_midi/'\n",
    "label_dict = dataset.create_label_dict_from_dir(csv_folder)\n",
    "for k,v in label_dict.items():\n",
    "    print(k,v.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = dataset.create_dataset_path_dict(csv_folder)\n",
    "dataset_paths_df = pd.DataFrame(dataset_paths).transpose()\n",
    "# dataset_paths_df.columns=['track_id', 'label_path', 'audio_path']\n",
    "display(dataset_paths_df.head(5))\n",
    "del dataset_paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label_gen = dataset.create_feature_label_generator(\n",
    "    dataset_path_dict=dataset_paths, \n",
    "    sample_rate= SAMPLE_RATE,\n",
    "    n_fft= N_FFT,\n",
    "    n_mels= N_MELS,\n",
    "    n_class= N_CLASS,\n",
    "    hop_length= HOP_LENGTH,\n",
    "    picking_frame_step= PICKING_FRAME_STEP,\n",
    "    picking_frame_size= PICKING_FRAME_SIZE,\n",
    "    step_frame= STEP_FRAME,\n",
    "    step_time= STEP_TIME,\n",
    "    dist_threshold= 0.1,\n",
    "    empty_threshold= 0.3,\n",
    ")\n",
    "passed_songs = []\n",
    "for song_name, feature_label_pair in feature_label_gen:\n",
    "    n_big_frame = 0\n",
    "    passed_songs.append(song_name)\n",
    "    for feature, label in feature_label_pair:\n",
    "        # print(feature.shape)\n",
    "        # print(label[0].shape)\n",
    "        # print(label[1].shape)\n",
    "        # print(label[2].shape)\n",
    "        n_big_frame+=1\n",
    "    print(song_name, n_big_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_label = []\n",
    "for label in dataset_paths:\n",
    "    if label not in passed_songs:\n",
    "        missing_label.append(label)\n",
    "missing_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3071ef67f0d52b8c9e2a13540b1ce413279ebac2bba14c7b121f8f9e6920f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
