{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchinfo\n",
    "\n",
    "from pitch_tracker.utils import dataset, files\n",
    "from pitch_tracker.utils.constants import (F_MIN, HOP_LENGTH, N_CLASS, N_FFT,\n",
    "                                           N_MELS, PICKING_FRAME_SIZE,\n",
    "                                           PICKING_FRAME_STEP,\n",
    "                                           PICKING_FRAME_TIME, SAMPLE_RATE,\n",
    "                                           STEP_FRAME, STEP_TIME, WIN_LENGTH)\n",
    "from pitch_tracker.utils.dataset import AudioDataset\n",
    "from pitch_tracker.ml.net import create_conv2d_block\n",
    "from pitch_tracker.ml.train_model import train_model, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() \\\n",
    "    else \"mps\" if torch.backends.mps.is_available() \\\n",
    "    else \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing tracks: 0 []\n",
      "Missing tracks: 0 []\n",
      "train_set: 54\n",
      "validation_set: 27\n",
      "test_set: 27\n"
     ]
    }
   ],
   "source": [
    "stft_hop_size = 512\n",
    "step_frame = 5\n",
    "onset_frame_time = stft_hop_size*step_frame/SAMPLE_RATE\n",
    "pick_frame_time = PICKING_FRAME_SIZE * onset_frame_time\n",
    "\n",
    "DATASET_DIR = f'../content/pickled_database/{stft_hop_size}_{step_frame}/'\n",
    "DATA_SPLIT_PATH = dataset.DATA_SPLIT_PATH\n",
    "\n",
    "train_df, validation_df, test_df = dataset.split_dataset_df('thesis', pickled_data_dir=DATASET_DIR)\n",
    "train_set, validation_set, test_set = train_df['pickled_path'], validation_df['pickled_path'], test_df['pickled_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(train_set)\n",
    "validation_dataset = AudioDataset(validation_set)\n",
    "test_dataset = AudioDataset(test_set)\n",
    "\n",
    "# affect GPU dedicated memory\n",
    "batch_size = 4\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_Model, self).__init__()\n",
    "        self.conv2d_block1 = create_conv2d_block(\n",
    "            conv2d_input=(1,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=None,\n",
    "        )\n",
    "        \n",
    "        self.conv2d_block2 = create_conv2d_block(\n",
    "            conv2d_input=(64,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "\n",
    "        self.conv2d_block3 = create_conv2d_block(\n",
    "            conv2d_input=(64,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "        \n",
    "        self.conv2d_block4 = create_conv2d_block(\n",
    "            conv2d_input=(64,210,3),\n",
    "            padding='same',\n",
    "            # maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = nn.Flatten(start_dim=2)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=3150,\n",
    "            hidden_size=88,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.dense_layer = nn.Linear(88,88)\n",
    "        # self.output_layer = nn.Linear(128, 88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_block1(x)\n",
    "        x = self.conv2d_block2(x)\n",
    "        x = self.conv2d_block3(x)\n",
    "        x = self.conv2d_block4(x)\n",
    "        flat = self.flatten_layer(x)\n",
    "        sequence, h_n = self.gru(flat)\n",
    "        out = self.dense_layer(sequence)\n",
    "        # x = self.output_layer(x)\n",
    "        return out\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: (1, 1, 1050, 88)\n",
      "Output size: (1, 210, 88)\n"
     ]
    }
   ],
   "source": [
    "model = Test_Model().to('cpu')\n",
    "dummy_in_shape = [1] + list(train_dataset.__getitem__(0)[0].shape)\n",
    "dummy_in = torch.randn(dummy_in_shape)\n",
    "print(f'Input size: {tuple(dummy_in.shape)}')\n",
    "print(f'Output size: {tuple(model(dummy_in).shape)}')\n",
    "# del dummy_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Test_Model                               [1, 210, 88]              --\n",
       "├─Sequential: 1-1                        [1, 64, 1050, 88]         --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 1050, 88]         640\n",
       "│    └─ReLU: 2-2                         [1, 64, 1050, 88]         --\n",
       "│    └─BatchNorm2d: 2-3                  [1, 64, 1050, 88]         128\n",
       "├─Sequential: 1-2                        [1, 64, 1050, 17]         --\n",
       "│    └─Conv2d: 2-4                       [1, 64, 1050, 88]         36,928\n",
       "│    └─ReLU: 2-5                         [1, 64, 1050, 88]         --\n",
       "│    └─BatchNorm2d: 2-6                  [1, 64, 1050, 88]         128\n",
       "│    └─MaxPool2d: 2-7                    [1, 64, 1050, 17]         --\n",
       "├─Sequential: 1-3                        [1, 64, 1050, 3]          --\n",
       "│    └─Conv2d: 2-8                       [1, 64, 1050, 17]         36,928\n",
       "│    └─ReLU: 2-9                         [1, 64, 1050, 17]         --\n",
       "│    └─BatchNorm2d: 2-10                 [1, 64, 1050, 17]         128\n",
       "│    └─MaxPool2d: 2-11                   [1, 64, 1050, 3]          --\n",
       "├─Sequential: 1-4                        [1, 210, 1050, 3]         --\n",
       "│    └─Conv2d: 2-12                      [1, 210, 1050, 3]         121,170\n",
       "│    └─ReLU: 2-13                        [1, 210, 1050, 3]         --\n",
       "│    └─BatchNorm2d: 2-14                 [1, 210, 1050, 3]         420\n",
       "├─Flatten: 1-5                           [1, 210, 3150]            --\n",
       "├─GRU: 1-6                               [1, 210, 88]              855,360\n",
       "├─Linear: 1-7                            [1, 210, 88]              7,832\n",
       "==========================================================================================\n",
       "Total params: 1,059,662\n",
       "Trainable params: 1,059,662\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.37\n",
       "Forward/backward pass size (MB): 218.39\n",
       "Params size (MB): 4.24\n",
       "Estimated Total Size (MB): 223.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_size=dummy_in_shape, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Test_Model().to(device)\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tien.d/workspace/GITHUB/mono_pitch_tracker/pitch_tracker/ml/train_model.py:49: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  batch_correct = torch.nonzero(pos_neg_arr).numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1/  191]  Batch Accuracy: 0.0%, current loss:     nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     train(model, validation_dataloader,loss_fn, optimizer, device)\n\u001b[1;32m      5\u001b[0m     test(model, test_dataloader, loss_fn, device)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/GITHUB/mono_pitch_tracker/pitch_tracker/ml/train_model.py:60\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     58\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 60\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     63\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mbatch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m>5d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtotal_batches\u001b[39m:\u001b[39;00m\u001b[39m>5d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m]  Batch Accuracy: \u001b[39m\u001b[39m{\u001b[39;00m(\u001b[39m100\u001b[39m\u001b[39m*\u001b[39mbatch_accuracy)\u001b[39m:\u001b[39;00m\u001b[39m>0.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%, current loss: \u001b[39m\u001b[39m{\u001b[39;00mrunning_loss\u001b[39m/\u001b[39m(batch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m:\u001b[39;00m\u001b[39m>7f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(model, validation_dataloader,loss_fn, optimizer, device)\n",
    "    test(model, test_dataloader, loss_fn, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.300722 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, test_dataloader, loss_fn, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, (y1,y2,y3) = next(iter(train_dataloader))\n",
    "X = X.to(device)\n",
    "y3 = y3.to(device)\n",
    "y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]]], device='mps:0',\n",
       "       grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3071ef67f0d52b8c9e2a13540b1ce413279ebac2bba14c7b121f8f9e6920f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
