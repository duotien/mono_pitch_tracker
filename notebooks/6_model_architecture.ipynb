{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniconda3\\envs\\mpt_2022\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\Spaceship420\\MY GIT\\mono_pitch_tracker\\medleydb\\medleydb\\__init__.py:69: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  INST_TAXONOMY = yaml.load(fhandle)\n",
      "E:\\Spaceship420\\MY GIT\\mono_pitch_tracker\\medleydb\\medleydb\\__init__.py:77: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  MIXING_COEFFICIENTS = yaml.load(fhandle)\n",
      "WARNING:sox:SoX could not be found!\n",
      "\n",
      "    If you do not have SoX, proceed here:\n",
      "     - - - http://sox.sourceforge.net/ - - -\n",
      "\n",
      "    If you do (or think that you should) have SoX, double-check your\n",
      "    path variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pitch_tracker.utils import dataset, files\n",
    "from pitch_tracker.utils.constants import (F_MIN, HOP_LENGTH, N_CLASS, N_FFT,\n",
    "                                           N_MELS, PICKING_FRAME_SIZE,\n",
    "                                           PICKING_FRAME_STEP,\n",
    "                                           PICKING_FRAME_TIME, SAMPLE_RATE,\n",
    "                                           STEP_FRAME, STEP_TIME, WIN_LENGTH)\n",
    "from pitch_tracker.utils.dataset import AudioDataset\n",
    "from pitch_tracker.ml.model.net import NeuralNetwork\n",
    "from pitch_tracker.ml. import train_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() \\\n",
    "    else \"mps\" if torch.backends.mps.is_available() \\\n",
    "    else \"cpu\"\n",
    "\n",
    "# device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_song_set: 64\n",
      "validation_song_set: 22\n",
      "test_song_set: 22\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = '../content/pickled_database/'\n",
    "\n",
    "dataset_paths = list(files.list_folder_paths_in_dir(DATASET_DIR))\n",
    "train_set, validation_set = train_test_split(dataset_paths, test_size=0.40, random_state=1, shuffle=True)\n",
    "validation_set, test_set = train_test_split(validation_set, test_size=0.50, random_state=1, shuffle=True)\n",
    "print(f'train_song_set: {len(train_set)}')\n",
    "print(f'validation_song_set: {len(validation_set)}')\n",
    "print(f'test_song_set: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(train_set)\n",
    "validation_dataset = AudioDataset(validation_set)\n",
    "test_dataset = AudioDataset(test_set)\n",
    "\n",
    "# affect GPU dedicated memory\n",
    "batch_size = 4\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniconda3\\envs\\mpt_2022\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 6.2%, current loss: 13.060298\n",
      "[   50/  648]  Batch Accuracy: 0.0%, current loss: 641.974011\n",
      "[   99/  648]  Batch Accuracy: 0.5%, current loss: 1269.609948\n",
      "[  148/  648]  Batch Accuracy: 0.0%, current loss: 1896.429015\n",
      "[  197/  648]  Batch Accuracy: 0.0%, current loss: 2522.489054\n",
      "[  246/  648]  Batch Accuracy: 0.0%, current loss: 3148.550686\n",
      "[  295/  648]  Batch Accuracy: 1.4%, current loss: 3774.858865\n",
      "[  344/  648]  Batch Accuracy: 1.4%, current loss: 4400.766545\n",
      "[  393/  648]  Batch Accuracy: 1.0%, current loss: 5026.630705\n",
      "[  442/  648]  Batch Accuracy: 0.0%, current loss: 5653.060153\n",
      "[  491/  648]  Batch Accuracy: 0.0%, current loss: 6279.430711\n",
      "[  540/  648]  Batch Accuracy: 1.0%, current loss: 6904.975354\n",
      "[  589/  648]  Batch Accuracy: 0.0%, current loss: 7530.056245\n",
      "[  638/  648]  Batch Accuracy: 0.0%, current loss: 8155.244347\n",
      "[  648/  648]  Total Accuracy: 2.9%, Avg loss: 12.781859\n",
      "Test Error: \n",
      " Accuracy: 7.9%, Avg loss: 12.775410 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 5.7%, current loss: 12.732586\n",
      "[   50/  648]  Batch Accuracy: 1.9%, current loss: 636.010792\n",
      "[   99/  648]  Batch Accuracy: 15.2%, current loss: 1261.474238\n",
      "[  148/  648]  Batch Accuracy: 0.0%, current loss: 1885.896948\n",
      "[  197/  648]  Batch Accuracy: 1.9%, current loss: 2509.974974\n",
      "[  246/  648]  Batch Accuracy: 20.0%, current loss: 3133.821954\n",
      "[  295/  648]  Batch Accuracy: 1.0%, current loss: 3758.249295\n",
      "[  344/  648]  Batch Accuracy: 16.2%, current loss: 4380.780211\n",
      "[  393/  648]  Batch Accuracy: 2.4%, current loss: 5005.056330\n",
      "[  442/  648]  Batch Accuracy: 1.9%, current loss: 5629.911627\n",
      "[  491/  648]  Batch Accuracy: 0.5%, current loss: 6254.119195\n",
      "[  540/  648]  Batch Accuracy: 0.0%, current loss: 6877.841961\n",
      "[  589/  648]  Batch Accuracy: 9.0%, current loss: 7501.339858\n",
      "[  638/  648]  Batch Accuracy: 15.2%, current loss: 8123.633852\n",
      "[  648/  648]  Total Accuracy: 11.1%, Avg loss: 12.733689\n",
      "Test Error: \n",
      " Accuracy: 16.8%, Avg loss: 12.841370 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 11.0%, current loss: 12.679253\n",
      "[   50/  648]  Batch Accuracy: 1.4%, current loss: 634.861170\n",
      "[   99/  648]  Batch Accuracy: 25.2%, current loss: 1257.053933\n",
      "[  148/  648]  Batch Accuracy: 28.1%, current loss: 1878.128170\n",
      "[  197/  648]  Batch Accuracy: 16.7%, current loss: 2498.001874\n",
      "[  246/  648]  Batch Accuracy: 3.3%, current loss: 3120.616410\n",
      "[  295/  648]  Batch Accuracy: 0.5%, current loss: 3741.851699\n",
      "[  344/  648]  Batch Accuracy: 1.9%, current loss: 4364.626686\n",
      "[  393/  648]  Batch Accuracy: 1.9%, current loss: 4985.296106\n",
      "[  442/  648]  Batch Accuracy: 3.3%, current loss: 5607.770753\n",
      "[  491/  648]  Batch Accuracy: 19.0%, current loss: 6227.920678\n",
      "[  540/  648]  Batch Accuracy: 10.0%, current loss: 6850.854017\n",
      "[  589/  648]  Batch Accuracy: 1.9%, current loss: 7473.652807\n",
      "[  638/  648]  Batch Accuracy: 3.8%, current loss: 8095.544356\n",
      "[  648/  648]  Total Accuracy: 15.5%, Avg loss: 12.688634\n",
      "Test Error: \n",
      " Accuracy: 17.6%, Avg loss: 12.787212 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 0.5%, current loss: 12.636801\n",
      "[   50/  648]  Batch Accuracy: 7.1%, current loss: 630.691287\n",
      "[   99/  648]  Batch Accuracy: 14.3%, current loss: 1249.826701\n",
      "[  148/  648]  Batch Accuracy: 20.5%, current loss: 1866.342529\n",
      "[  197/  648]  Batch Accuracy: 0.0%, current loss: 2484.986111\n",
      "[  246/  648]  Batch Accuracy: 19.5%, current loss: 3102.756210\n",
      "[  295/  648]  Batch Accuracy: 17.1%, current loss: 3724.645131\n",
      "[  344/  648]  Batch Accuracy: 3.8%, current loss: 4346.746807\n",
      "[  393/  648]  Batch Accuracy: 10.5%, current loss: 4966.074415\n",
      "[  442/  648]  Batch Accuracy: 10.5%, current loss: 5585.423469\n",
      "[  491/  648]  Batch Accuracy: 13.3%, current loss: 6204.253271\n",
      "[  540/  648]  Batch Accuracy: 88.1%, current loss: 6826.613019\n",
      "[  589/  648]  Batch Accuracy: 47.6%, current loss: 7447.374155\n",
      "[  638/  648]  Batch Accuracy: 1.0%, current loss: 8067.179813\n",
      "[  648/  648]  Total Accuracy: 15.4%, Avg loss: 12.643786\n",
      "Test Error: \n",
      " Accuracy: 18.8%, Avg loss: 12.989635 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 38.1%, current loss: 12.532924\n",
      "[   50/  648]  Batch Accuracy: 34.3%, current loss: 626.257187\n",
      "[   99/  648]  Batch Accuracy: 1.4%, current loss: 1244.133220\n",
      "[  148/  648]  Batch Accuracy: 12.4%, current loss: 1861.405732\n",
      "[  197/  648]  Batch Accuracy: 22.9%, current loss: 2478.305085\n",
      "[  246/  648]  Batch Accuracy: 16.2%, current loss: 3093.101477\n",
      "[  295/  648]  Batch Accuracy: 12.9%, current loss: 3710.210399\n",
      "[  344/  648]  Batch Accuracy: 20.5%, current loss: 4329.406853\n",
      "[  393/  648]  Batch Accuracy: 10.0%, current loss: 4947.615245\n",
      "[  442/  648]  Batch Accuracy: 0.5%, current loss: 5564.017236\n",
      "[  491/  648]  Batch Accuracy: 11.4%, current loss: 6181.261605\n",
      "[  540/  648]  Batch Accuracy: 8.6%, current loss: 6798.273758\n",
      "[  589/  648]  Batch Accuracy: 100.0%, current loss: 7413.910154\n",
      "[  638/  648]  Batch Accuracy: 11.0%, current loss: 8033.598277\n",
      "[  648/  648]  Total Accuracy: 20.2%, Avg loss: 12.593157\n",
      "Test Error: \n",
      " Accuracy: 13.4%, Avg loss: 12.847432 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_model(model, validation_dataloader,loss_fn, optimizer, device)\n",
    "    test_model(model, test_dataloader, loss_fn, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.300722 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, validation_dataloader, loss_fn, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, (y1,y2,y3) = next(iter(train_dataloader))\n",
    "X = X.to(device)\n",
    "y3 = y3.to(device)\n",
    "y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2972,  0.3336, -0.1609,  ..., -0.0524, -0.0204, -0.8517],\n",
       "         [-0.1902,  0.0582,  0.1809,  ...,  0.0170,  0.2186, -0.5805],\n",
       "         [-0.3692, -0.0507,  0.0995,  ..., -0.0526,  0.0991, -0.6397],\n",
       "         ...,\n",
       "         [-0.5017, -0.3042, -0.5330,  ..., -0.0360, -0.4683,  0.2623],\n",
       "         [-0.4445,  0.0660, -0.5317,  ..., -0.0100, -0.4262,  0.6025],\n",
       "         [-0.2346, -0.5030, -0.2007,  ..., -0.0692,  0.0729, -0.1966]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(y_pred, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.041638374328613"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 210, 88])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.size()\n",
    "y3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73920"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([840])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.argmax(2).flatten() == y3.argmax(2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred.argmax(2) == y3.argmax(2)).type(torch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_matrix = (y_pred.argmax(2) == y3.argmax(2)).flatten()\n",
    "n_size = pos_neg_matrix.numel()\n",
    "n_correct = torch.nonzero(pos_neg_matrix).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230310-171903'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "date_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3071ef67f0d52b8c9e2a13540b1ce413279ebac2bba14c7b121f8f9e6920f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
