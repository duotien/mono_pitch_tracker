{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from pitch_tracker.utils import dataset\n",
    "from pitch_tracker.utils.dataset import AudioDataset\n",
    "from pitch_tracker.utils.constants import (F_MIN, HOP_LENGTH, N_FFT, N_MELS,\n",
    "                                           PICKING_FRAME_SIZE,\n",
    "                                           PICKING_FRAME_STEP,\n",
    "                                           PICKING_FRAME_TIME, SAMPLE_RATE,\n",
    "                                           STEP_FRAME, STEP_TIME, WIN_LENGTH,\n",
    "                                           N_CLASS, )\n",
    "from pitch_tracker.utils import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '../content/pickled_database/'\n",
    "\n",
    "\n",
    "dataset_paths = list(files.list_folder_paths_in_dir(DATASET_DIR))\n",
    "train_set, validation_set = train_test_split(dataset_paths, test_size=0.40, random_state=1, shuffle=True)\n",
    "validation_set, test_set = train_test_split(validation_set, test_size=0.50, random_state=1, shuffle=True)\n",
    "print(f'train_song_set: {len(train_set)}')\n",
    "print(f'validation_song_set: {len(validation_set)}')\n",
    "print(f'test_song_set: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(train_set)\n",
    "validation_set = AudioDataset(validation_set)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() \\\n",
    "    else \"mps\" if torch.backends.mps.is_available() \\\n",
    "    else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Tuple, Union\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def create_conv2d_block(\n",
    "        conv2d_input: Tuple[int,int,Union[Tuple[int,int], int]],\n",
    "        maxpool_kernel_size: Union[Tuple[int,int], int, None],):\n",
    "    in_channels, out_channels, (kernel_size) = conv2d_input\n",
    "    \n",
    "    conv2d = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "    relu = nn.ReLU()\n",
    "    batch_norm = nn.BatchNorm2d(out_channels)\n",
    "    maxpool_2d = nn.MaxPool2d(maxpool_kernel_size) if maxpool_kernel_size else None\n",
    "    \n",
    "    conv2d_block = nn.Sequential(\n",
    "        OrderedDict([\n",
    "            ('conv2d', conv2d),\n",
    "            ('relu', relu),\n",
    "            ('batch_norm', batch_norm),  \n",
    "        ])\n",
    "    )\n",
    "\n",
    "    if maxpool_2d:\n",
    "        conv2d_block.add_module('maxpool2d', maxpool_2d)\n",
    "    \n",
    "    return conv2d_block\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv2d_block1 = create_conv2d_block(\n",
    "            conv2d_input=(1,256,3),\n",
    "            maxpool_kernel_size=3,\n",
    "        )\n",
    "        \n",
    "        self.conv2d_block2 = create_conv2d_block(\n",
    "            conv2d_input=(256,256,3),\n",
    "            maxpool_kernel_size=3,\n",
    "        )\n",
    "\n",
    "        self.conv2d_block3 = create_conv2d_block(\n",
    "            conv2d_input=(256,210,3),\n",
    "            maxpool_kernel_size=3,\n",
    "        )\n",
    "        # self.unflatten_layer = nn.Unflatten(1, (210,-1))\n",
    "        # self.reshape_layer = partial(torch.reshape, shape=(8,210,-1))\n",
    "        self.flatten_layer = torch.nn.Flatten(2)\n",
    "        self.dense_layer = nn.LazyLinear(512)\n",
    "        self.output_layer = nn.Linear(512, 88)\n",
    "        self.softmax_layer = nn.Softmax(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_block1(x)\n",
    "        x = self.conv2d_block2(x)\n",
    "        x = self.conv2d_block3(x)\n",
    "        # x = self.unflatten_layer(x)\n",
    "        # x = self.reshape_layer(x)\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.softmax_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = nn.LazyLinear(256).to(device)\n",
    "sample_feature, sample_label = next(iter(train_dataloader))\n",
    "pred = model(sample_feature.to(device))\n",
    "print(pred.shape)\n",
    "print(nn.Flatten(2)(pred).shape)\n",
    "# loss_fn(pred, sample_label[2])\n",
    "print(sample_feature.shape)\n",
    "print(sample_label[2].shape)\n",
    "# pred = dense_layer(pred)\n",
    "# pred.reshape((8,210,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.binary_cross_entropy_with_logits(pred.to(device), sample_label[2].to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, (y1, y2, y3)) in enumerate(dataloader):\n",
    "        X, y3 = X.to(device), y3.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y3)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        loss, current = loss.item(), (batch + 1) * len(X)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, (y1,y2,y3) in dataloader:\n",
    "            X, y3 = X.to(device), y3.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y3).item()\n",
    "            correct += (pred.argmax(2) == y3.argmax(2)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= (size*210)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pred.argmax(2))\n",
    "# print(sample_label[2].argmax(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(torch.Tensor(([0,0,0,1],[0,1,0,0])), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(validation_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, (X, (y1, y2, y3)) in enumerate(train_dataloader):\n",
    "    print(y3.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3071ef67f0d52b8c9e2a13540b1ce413279ebac2bba14c7b121f8f9e6920f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
