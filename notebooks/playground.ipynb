{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tien.d/workspace/GITHUB/mono_pitch_tracker/medleydb/medleydb/__init__.py:69: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  INST_TAXONOMY = yaml.load(fhandle)\n",
      "/Users/tien.d/workspace/GITHUB/mono_pitch_tracker/medleydb/medleydb/__init__.py:77: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  MIXING_COEFFICIENTS = yaml.load(fhandle)\n"
     ]
    }
   ],
   "source": [
    "from pitch_tracker.ml.model.net import Audio_CNN, Audio_CRNN, create_conv2d_block, conv2d_output_shape\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_Model, self).__init__()\n",
    "        self.conv2d_block1 = create_conv2d_block(\n",
    "            conv2d_input=(1,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=None,\n",
    "        )\n",
    "        \n",
    "        self.conv2d_block2 = create_conv2d_block(\n",
    "            conv2d_input=(64,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "\n",
    "        self.conv2d_block3 = create_conv2d_block(\n",
    "            conv2d_input=(64,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "        \n",
    "        self.conv2d_block4 = create_conv2d_block(\n",
    "            conv2d_input=(64,210,3),\n",
    "            padding='same',\n",
    "            # maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = nn.Flatten(start_dim=2)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=3150,\n",
    "            hidden_size=88,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.dense_layer = nn.Linear(88,88)\n",
    "        # self.output_layer = nn.Linear(128, 88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_block1(x)\n",
    "        x = self.conv2d_block2(x)\n",
    "        x = self.conv2d_block3(x)\n",
    "        x = self.conv2d_block4(x)\n",
    "        flat = self.flatten_layer(x)\n",
    "        sequence, h_n = self.gru(flat)\n",
    "        out = self.dense_layer(sequence)\n",
    "        # x = self.output_layer(x)\n",
    "        return out\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Model(\n",
      "  (conv2d_block1): Sequential(\n",
      "    (conv2d): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (relu): ReLU()\n",
      "    (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2d_block2): Sequential(\n",
      "    (conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (relu): ReLU()\n",
      "    (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (maxpool2d): MaxPool2d(kernel_size=(1, 5), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2d_block3): Sequential(\n",
      "    (conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (relu): ReLU()\n",
      "    (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (maxpool2d): MaxPool2d(kernel_size=(1, 5), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2d_block4): Sequential(\n",
      "    (conv2d): Conv2d(64, 210, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (relu): ReLU()\n",
      "    (batch_norm): BatchNorm2d(210, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flatten_layer): Flatten(start_dim=2, end_dim=-1)\n",
      "  (gru): GRU(3150, 88, batch_first=True, dropout=0.2)\n",
      "  (dense_layer): Linear(in_features=88, out_features=88, bias=True)\n",
      ")\n",
      "torch.Size([4, 210, 88])\n"
     ]
    }
   ],
   "source": [
    "model = Test_Model()\n",
    "print(model)\n",
    "dummy_input = torch.randn((4,1,1050,88))\n",
    "out = model(dummy_input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Test_Model                               [4, 210, 88]              --\n",
       "├─Sequential: 1-1                        [4, 64, 1050, 88]         --\n",
       "│    └─Conv2d: 2-1                       [4, 64, 1050, 88]         640\n",
       "│    └─ReLU: 2-2                         [4, 64, 1050, 88]         --\n",
       "│    └─BatchNorm2d: 2-3                  [4, 64, 1050, 88]         128\n",
       "├─Sequential: 1-2                        [4, 64, 1050, 17]         --\n",
       "│    └─Conv2d: 2-4                       [4, 64, 1050, 88]         36,928\n",
       "│    └─ReLU: 2-5                         [4, 64, 1050, 88]         --\n",
       "│    └─BatchNorm2d: 2-6                  [4, 64, 1050, 88]         128\n",
       "│    └─MaxPool2d: 2-7                    [4, 64, 1050, 17]         --\n",
       "├─Sequential: 1-3                        [4, 64, 1050, 3]          --\n",
       "│    └─Conv2d: 2-8                       [4, 64, 1050, 17]         36,928\n",
       "│    └─ReLU: 2-9                         [4, 64, 1050, 17]         --\n",
       "│    └─BatchNorm2d: 2-10                 [4, 64, 1050, 17]         128\n",
       "│    └─MaxPool2d: 2-11                   [4, 64, 1050, 3]          --\n",
       "├─Sequential: 1-4                        [4, 210, 1050, 3]         --\n",
       "│    └─Conv2d: 2-12                      [4, 210, 1050, 3]         121,170\n",
       "│    └─ReLU: 2-13                        [4, 210, 1050, 3]         --\n",
       "│    └─BatchNorm2d: 2-14                 [4, 210, 1050, 3]         420\n",
       "├─Flatten: 1-5                           [4, 210, 3150]            --\n",
       "├─GRU: 1-6                               [4, 210, 88]              855,360\n",
       "├─Linear: 1-7                            [4, 210, 88]              7,832\n",
       "==========================================================================================\n",
       "Total params: 1,059,662\n",
       "Trainable params: 1,059,662\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 18.77\n",
       "==========================================================================================\n",
       "Input size (MB): 1.48\n",
       "Forward/backward pass size (MB): 873.57\n",
       "Params size (MB): 4.24\n",
       "Estimated Total Size (MB): 879.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(4, 1, 1050, 88))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    # dataset\n",
    "    'batch_size': 4,\n",
    "    # fit\n",
    "    'n_epochs': 5,\n",
    "    'learning_rate': 1e-3,\n",
    "    # early stopping\n",
    "    'es_patience': 10,\n",
    "    'es_verbose': True,\n",
    "    'es_dir_path': './checkpoints',\n",
    "    # lr scheduler\n",
    "    'ls_patience': 8,\n",
    "    'ls_factor': 0.2,\n",
    "    # misc\n",
    "    'device': 'DEVICE',\n",
    "}\n",
    "\n",
    "with open('config.yaml', 'w') as f:\n",
    "    yaml.dump(p,f,sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input.1 : Float(4, 1, 1050, 88, strides=[92400, 92400, 88, 1], requires_grad=0, device=cpu),\n",
      "      %conv2d_block1.conv2d.weight : Float(256, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block1.conv2d.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block1.batch_norm.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block1.batch_norm.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block1.batch_norm.running_mean : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %conv2d_block1.batch_norm.running_var : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %conv2d_block2.conv2d.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block2.conv2d.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block2.batch_norm.running_mean : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %conv2d_block2.batch_norm.running_var : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %conv2d_block3.conv2d.weight : Float(210, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block3.conv2d.bias : Float(210, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block3.batch_norm.weight : Float(210, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block3.batch_norm.bias : Float(210, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2d_block3.batch_norm.running_mean : Float(210, strides=[1], requires_grad=0, device=cpu),\n",
      "      %conv2d_block3.batch_norm.running_var : Float(210, strides=[1], requires_grad=0, device=cpu),\n",
      "      %dense_layer.bias : Float(88, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::GRU_139 : Float(1, 264, 920, strides=[242880, 920, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::GRU_140 : Float(1, 264, 88, strides=[23232, 88, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::GRU_141 : Float(1, 528, strides=[528, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_143 : Float(88, 88, strides=[1, 88], requires_grad=0, device=cpu)):\n",
      "  %conv2d_block2.batch_norm.bias : Float(256, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%conv2d_block1.batch_norm.bias)\n",
      "  %conv2d_block2.batch_norm.weight : Float(256, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%conv2d_block1.batch_norm.weight)\n",
      "  %/conv2d_block1/conv2d/Conv_output_0 : Float(4, 256, 1048, 86, strides=[23072768, 90128, 86, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/conv2d_block1/conv2d/Conv\"](%input.1, %conv2d_block1.conv2d.weight, %conv2d_block1.conv2d.bias), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block1/torch.nn.modules.conv.Conv2d::conv2d # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/conv2d_block1/relu/Relu_output_0 : Float(4, 256, 1048, 86, strides=[23072768, 90128, 86, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/conv2d_block1/relu/Relu\"](%/conv2d_block1/conv2d/Conv_output_0), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block1/torch.nn.modules.activation.ReLU::relu # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:1457:0\n",
      "  %/conv2d_block1/batch_norm/BatchNormalization_output_0 : Float(4, 256, 1048, 86, strides=[23072768, 90128, 86, 1], requires_grad=1, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"/conv2d_block1/batch_norm/BatchNormalization\"](%/conv2d_block1/relu/Relu_output_0, %conv2d_block1.batch_norm.weight, %conv2d_block1.batch_norm.bias, %conv2d_block1.batch_norm.running_mean, %conv2d_block1.batch_norm.running_var), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block1/torch.nn.modules.batchnorm.BatchNorm2d::batch_norm # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:2450:0\n",
      "  %/conv2d_block2/conv2d/Conv_output_0 : Float(4, 256, 1046, 84, strides=[22493184, 87864, 84, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/conv2d_block2/conv2d/Conv\"](%/conv2d_block1/batch_norm/BatchNormalization_output_0, %conv2d_block2.conv2d.weight, %conv2d_block2.conv2d.bias), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block2/torch.nn.modules.conv.Conv2d::conv2d # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/conv2d_block2/relu/Relu_output_0 : Float(4, 256, 1046, 84, strides=[22493184, 87864, 84, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/conv2d_block2/relu/Relu\"](%/conv2d_block2/conv2d/Conv_output_0), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block2/torch.nn.modules.activation.ReLU::relu # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:1457:0\n",
      "  %/conv2d_block2/batch_norm/BatchNormalization_output_0 : Float(4, 256, 1046, 84, strides=[22493184, 87864, 84, 1], requires_grad=1, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"/conv2d_block2/batch_norm/BatchNormalization\"](%/conv2d_block2/relu/Relu_output_0, %conv2d_block2.batch_norm.weight, %conv2d_block2.batch_norm.bias, %conv2d_block2.batch_norm.running_mean, %conv2d_block2.batch_norm.running_var), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block2/torch.nn.modules.batchnorm.BatchNorm2d::batch_norm # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:2450:0\n",
      "  %/conv2d_block2/maxpool2d/MaxPool_output_0 : Float(4, 256, 348, 28, strides=[2494464, 9744, 28, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[3, 3], onnx_name=\"/conv2d_block2/maxpool2d/MaxPool\"](%/conv2d_block2/batch_norm/BatchNormalization_output_0), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block2/torch.nn.modules.pooling.MaxPool2d::maxpool2d # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:782:0\n",
      "  %/conv2d_block3/conv2d/Conv_output_0 : Float(4, 210, 346, 26, strides=[1889160, 8996, 26, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/conv2d_block3/conv2d/Conv\"](%/conv2d_block2/maxpool2d/MaxPool_output_0, %conv2d_block3.conv2d.weight, %conv2d_block3.conv2d.bias), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block3/torch.nn.modules.conv.Conv2d::conv2d # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/conv2d_block3/relu/Relu_output_0 : Float(4, 210, 346, 26, strides=[1889160, 8996, 26, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/conv2d_block3/relu/Relu\"](%/conv2d_block3/conv2d/Conv_output_0), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block3/torch.nn.modules.activation.ReLU::relu # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:1457:0\n",
      "  %/conv2d_block3/batch_norm/BatchNormalization_output_0 : Float(4, 210, 346, 26, strides=[1889160, 8996, 26, 1], requires_grad=1, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"/conv2d_block3/batch_norm/BatchNormalization\"](%/conv2d_block3/relu/Relu_output_0, %conv2d_block3.batch_norm.weight, %conv2d_block3.batch_norm.bias, %conv2d_block3.batch_norm.running_mean, %conv2d_block3.batch_norm.running_var), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block3/torch.nn.modules.batchnorm.BatchNorm2d::batch_norm # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:2450:0\n",
      "  %/conv2d_block3/maxpool2d/MaxPool_output_0 : Float(4, 210, 115, 8, strides=[193200, 920, 8, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[3, 3], onnx_name=\"/conv2d_block3/maxpool2d/MaxPool\"](%/conv2d_block3/batch_norm/BatchNormalization_output_0), scope: __main__.Test_Model::/torch.nn.modules.container.Sequential::conv2d_block3/torch.nn.modules.pooling.MaxPool2d::maxpool2d # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:782:0\n",
      "  %/flatten_layer/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/flatten_layer/Shape\"](%/conv2d_block3/maxpool2d/MaxPool_output_0), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/flatten_layer/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/flatten_layer/Constant\"](), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/flatten_layer/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/flatten_layer/Constant_1\"](), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/flatten_layer/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/flatten_layer/Constant_2\"](), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/flatten_layer/Slice_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/flatten_layer/Slice\"](%/flatten_layer/Shape_output_0, %/flatten_layer/Constant_1_output_0, %/flatten_layer/Constant_2_output_0, %/flatten_layer/Constant_output_0), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/flatten_layer/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/flatten_layer/Constant_3\"](), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/flatten_layer/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/flatten_layer/Concat\"](%/flatten_layer/Slice_output_0, %/flatten_layer/Constant_3_output_0), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/flatten_layer/Reshape_output_0 : Float(4, 210, 920, strides=[193200, 920, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"/flatten_layer/Reshape\"](%/conv2d_block3/maxpool2d/MaxPool_output_0, %/flatten_layer/Concat_output_0), scope: __main__.Test_Model::/torch.nn.modules.flatten.Flatten::flatten_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %/gru/Constant_output_0 : Float(1, 4, 88, strides=[352, 88, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/gru/Constant\"](), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:945:0\n",
      "  %/gru/Transpose_output_0 : Float(210, 4, 920, strides=[3680, 920, 1], device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/gru/Transpose\"](%/flatten_layer/Reshape_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %onnx::GRU_49 : Tensor? = prim::Constant(), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/gru/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/gru/Shape\"](%/gru/Transpose_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/gru/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/gru/Constant_1\"](), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/gru/Gather_output_0 : Long(device=cpu) = onnx::Gather[onnx_name=\"/gru/Gather\"](%/gru/Shape_output_0, %/gru/Constant_1_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %onnx::Concat_109 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%/gru/Gather_output_0)\n",
      "  %/gru/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={88}, onnx_name=\"/gru/Constant_2\"](), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %onnx::Concat_142 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %/gru/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/gru/Concat\"](%onnx::Concat_142, %onnx::Concat_109, %/gru/Constant_2_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/gru/Expand_output_0 : Float(1, 4, 88, strides=[352, 88, 1], device=cpu) = onnx::Expand[onnx_name=\"/gru/Expand\"](%/gru/Constant_output_0, %/gru/Concat_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/gru/GRU_output_0 : Float(210, 1, 4, 88, strides=[352, 352, 88, 1], device=cpu), %/gru/GRU_output_1 : Float(1, 4, 88, strides=[352, 88, 1], requires_grad=1, device=cpu) = onnx::GRU[hidden_size=88, linear_before_reset=1, onnx_name=\"/gru/GRU\"](%/gru/Transpose_output_0, %onnx::GRU_139, %onnx::GRU_140, %onnx::GRU_141, %onnx::GRU_49, %/gru/Expand_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/gru/Squeeze_output_0 : Float(210, 4, 88, strides=[352, 88, 1], device=cpu) = onnx::Squeeze[axes=[1], onnx_name=\"/gru/Squeeze\"](%/gru/GRU_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/gru/Transpose_1_output_0 : Float(4, 210, 88, strides=[88, 352, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/gru/Transpose_1\"](%/gru/Squeeze_output_0), scope: __main__.Test_Model::/torch.nn.modules.rnn.GRU::gru # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955:0\n",
      "  %/dense_layer/MatMul_output_0 : Float(4, 210, 88, strides=[18480, 88, 1], device=cpu) = onnx::MatMul[onnx_name=\"/dense_layer/MatMul\"](%/gru/Transpose_1_output_0, %onnx::MatMul_143), scope: __main__.Test_Model::/torch.nn.modules.linear.Linear::dense_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %output1 : Float(4, 210, 88, strides=[18480, 88, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/dense_layer/Add\"](%dense_layer.bias, %/dense_layer/MatMul_output_0), scope: __main__.Test_Model::/torch.nn.modules.linear.Linear::dense_layer # /Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%output1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:4315: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with GRU can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "/Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "in_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "out_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    f=\"dummy_model.onnx\",\n",
    "    # input_names=in_names,\n",
    "    output_names=out_names,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3071ef67f0d52b8c9e2a13540b1ce413279ebac2bba14c7b121f8f9e6920f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
